{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a Memory-Enhanced Email Agent with LangGraph\n",
    "This tutorial demonstrates how to build an advanced AI agent with three types of memory using LangGraph and LangMem. We'll create an email assistant that can remember important facts, learn from past examples, and improve its behavior based on feedback.\n",
    "\n",
    "Key Memory Types:\n",
    "Semantic Memory: Stores facts and knowledge about contacts, preferences, and contexts\n",
    "Episodic Memory: Remembers specific past interactions and examples\n",
    "Procedural Memory: Learns and improves behavioral patterns over time\n",
    "Tutorial Overview: Email Assistant with Memory\n",
    "In this tutorial, we'll build an email agent that can:\n",
    "\n",
    "Triage emails: Classify incoming emails as 'ignore', 'notify', or 'respond'\n",
    "Draft responses: Compose contextually appropriate replies using stored knowledge\n",
    "Learn from feedback: Improve its performance based on user corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Literal, Annotated, List\n",
    "from langgraph.graph import StateGraph, START, END, add_messages\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.store.memory import InMemoryStore  # For storing memories\n",
    "from langmem import create_manage_memory_tool, create_search_memory_tool # LangMem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kylestanford/Library/CloudStorage/OneDrive-Partners/Documents/GitHub/World_of_Agents/agent_world_venv/lib/python3.12/site-packages/langgraph/store/base/embed.py:95: LangChainBetaWarning: The function `init_embeddings` is in beta. It is actively being worked on, so the API may change.\n",
      "  return init_embeddings(embed)\n"
     ]
    }
   ],
   "source": [
    "# Load env variables (openAI api key)\n",
    "load_dotenv()\n",
    "\n",
    "# init LLM\n",
    "llm = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "\n",
    "# Init the meory store (we'll use an in-memory store for simplicity)\n",
    "store = InMemoryStore(index={\"embed\": \"openai:text-embedding-3-small\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the agent \"Brain\" State\n",
    "class State(TypedDict):\n",
    "    email_input: dict #Incoming email\n",
    "    messages: Annotated[list, add_messages] #The conversation history\n",
    "    triage_result: str #the result of the triage (ignore, notify, respond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triage center: Deciding what to do (Episodic Memory)\n",
    "class Router(BaseModel):\n",
    "    reasoning: str = Field(description=\"Step-by-step reasoning behind the classification.\")\n",
    "    classification: Literal[\"ignore\", \"respond\", \"notify\"] = Field(\n",
    "        description=\"The classification of an email: 'ignore', 'notify', or 'respond'.\"\n",
    "    )\n",
    "\n",
    "llm_router = llm.with_structured_output(Router)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhance triage_email function\n",
    "def format_few_shot_examples(examples):\n",
    "    formatted_examples = []\n",
    "    for eg in examples:\n",
    "        email = eg.value['email']\n",
    "        label = eg.value['label']\n",
    "        formatted_examples.append(\n",
    "            f\"From: {email['author']}\\nSubject: {email['subject']}\\nBody: {email['email_thread'][:300]}...\\n\\nClassification: {label}\"\n",
    "        )\n",
    "    return \"\\n\\n\".join(formatted_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_email(state: State, config: dict, store: InMemoryStore) -> dict:\n",
    "    email = state[\"email_input\"]\n",
    "    user_id = config[\"configurable\"][\"langgraph_user_id\"]\n",
    "    namespace = (\"email_assistant\", user_id, \"examples\") #Namespace for episodic memory\n",
    "\n",
    "    # Retrieve relevant examples from memory\n",
    "    examples = store.search(namespace, query=str(email))\n",
    "    formatted_examples = format_few_shot_examples(examples)\n",
    "\n",
    "    prompt_template = PromptTemplate.from_template(\"\"\"You are an email triage assistant.  Classify the following email:\n",
    "    From: {author}\n",
    "    To: {to}\n",
    "    Subject: {subject}\n",
    "    Body: {email_thread}\n",
    "\n",
    "    Classify as 'ignore', 'notify', or 'respond'.\n",
    "\n",
    "    Here are some examples of previous classifications:\n",
    "    {examples}\n",
    "    \"\"\")\n",
    "\n",
    "    prompt = prompt_template.format(examples=formatted_examples, **email)\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    result = llm_router.invoke(messages)\n",
    "    return {\"triage_result\": result.classification}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTION TIMEEEE\n",
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email\"\"\"\n",
    "    print(f\"Sending email to {to} with subject '{subject}'\\nContent:\\n{content}\\n\")\n",
    "    return f\"Email sent to {to} with subject '{subject}'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def check_calendar_availability(day: str) -> str:\n",
    "    \"\"\"Checl calendar availability for a given day\"\"\"\n",
    "    return f\"Availabl;e times on {day}: 9:00 AM, 2:00 PM, 4:00 PM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create langmem memory tools (using the configured user ID)\n",
    "manage_memory_tool = create_manage_memory_tool(namespace=(\"email_assistant\", \"{langgraph_user_id}\", \"collection\"))\n",
    "search_memory_tool = create_search_memory_tool(namespace=(\"email_assistant\", \"{langgraph_user_id}\", \"collection\"))\n",
    "\n",
    "tools = [write_email, check_calendar_availability, manage_memory_tool, search_memory_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response agent: Putting it all togeteher (with Semantic Memory!)\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "def create_agent_prompt(state, config, store):\n",
    "    messages = state['messages']\n",
    "    user_id = config[\"configurable\"][\"langgraph_user_id\"]\n",
    "\n",
    "    # Get the current response prompt from procedural memory\n",
    "    system_prompt = store.get((\"email_assistant\", user_id, \"prompts\"), \"response_prompt\").value\n",
    "\n",
    "    return [{\"role\": \"system\", \"content\": system_prompt}] + messages\n",
    "\n",
    "# Try using the current api signature\n",
    "response_agent = create_react_agent(\n",
    "    tools = tools,\n",
    "    prompt = create_agent_prompt,\n",
    "    store=store,\n",
    "    model=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the graph, connecting the pieces\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Update this line to pass the store to the node\n",
    "workflow.add_node(\"triage\", lambda state, config: triage_email(state, config, store))\n",
    "workflow.add_node(\"response_agent\", response_agent)\n",
    "\n",
    "def route_based_on_triage(state):\n",
    "    if state[\"triage_result\"] == \"respond\":\n",
    "        return \"response_agent\"\n",
    "    else:\n",
    "        return END\n",
    "    \n",
    "workflow.add_edge(START, \"triage\")\n",
    "workflow.add_conditional_edges(\"triage\", route_based_on_triage, {\n",
    "    \"response_agent\": \"response_agent\",\n",
    "    END: END\n",
    "})\n",
    "\n",
    "# compile the graph\n",
    "agent = workflow.compile(store=store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DISPLAY CURRENT AGENT\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from IPython.display import display, Image\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        agent.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding procedural Memory (updating instructions)\n",
    "initial_triage_prompt = \"\"\"You are an email triage assistant. Classify the following email:\n",
    "From: {author}\n",
    "To: {to}\n",
    "Subject: {subject}\n",
    "Body: {email_thread}\n",
    "\n",
    "Classify as 'ignore', 'notify', or 'respond'.\n",
    "\n",
    "Here are some examples of previous classifications:\n",
    "{examples}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_response_prompt = \"\"\"You are a helpful assistant. Use the tools available, including memory tools, to assist the user.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store these prompts in the meory state\n",
    "store.put((\"email_assistant\", \"test_user\", \"prompts\"), \"triage_prompt\", initial_triage_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.put((\"email_assistant\", \"test_user\", \"prompts\"), \"response_prompt\", initial_response_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_email_with_procedural_memory(state: State, config: dict, sotre: InMemoryStore) -> dict:\n",
    "    email = state[\"email_input\"]\n",
    "    user_id = config[\"configurable\"][\"langgraph_user_id\"]\n",
    "\n",
    "    # retrieve the current triage prompt (procedural memoyr)\n",
    "    current_prompt_template = store.get((\"email_assistant\", user_id, \"prompts\"), \"triage_prompt\").value\n",
    "\n",
    "    # Retrieve relevant eamples from memory (episodic memory)\n",
    "    namespace = (\"email_assistant\", user_id, \"examples\")\n",
    "    examples = store.search(namespace, query=str(email))\n",
    "    formatted_examples = format_few_shot_examples(examples)\n",
    "\n",
    "    # Format the prompt\n",
    "    prompt = PromptTemplate.from_template(current_prompt_template).format(examples=formatted_examples, **email)\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    result = llm_router.invoke(messages)\n",
    "    return {\"triage_result\": result.classification}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmem import create_multi_prompt_optimizer\n",
    "\n",
    "def optimize_prompts(feedback: str, config: dict, store: InMemoryStore):\n",
    "    \"\"\"Improve our prompts based on feedback\"\"\"\n",
    "    user_id = config[\"configurable\"][\"langgraph_user_id\"]\n",
    "\n",
    "    # Get the current prompts\n",
    "    triage_prompt = store.get((\"email_assistant\", user_id, \"prompts\"), \"triage_prompt\").value\n",
    "    response_prompt = store.get((\"email_assistant\", user_id, \"prompts\"), \"response_prompt\").value\n",
    "\n",
    "    # Create a more relevant test example base don our actual email\n",
    "    sample_email = {\n",
    "        \"author\": \"Alice Smith <alice.smith@company.com>\",\n",
    "        \"to\": \"John Doe <john.doe@company.com>\",\n",
    "        \"subject\": \"Quick question about API documentation\",\n",
    "        \"email_thread\": \"Hi John, I was reviewing the API documentation and noticed a few endpoints are missing. Could you help? Thanks, Alice\",\n",
    "    }\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = create_multi_prompt_optimizer(llm)\n",
    "\n",
    "    # Create a more relevant conversation trajectory with feedback\n",
    "    conversation = [\n",
    "        {\"role\": \"system\", \"content\": response_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"I received this email: {sample_email}\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"How can I assist you today?\"}\n",
    "    ]\n",
    "\n",
    "    # Format prompts\n",
    "    prompts = [\n",
    "        {\"name\": \"triage\", \"prompt\": triage_prompt},\n",
    "        {\"name\": \"response\", \"prompt\": response_prompt}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # More relevant trajectories \n",
    "        trajectories = [(conversation, {\"feedback\": feedback})]\n",
    "        result = optimizer.invoke({\"trajectories\": trajectories, \"prompts\": prompts})\n",
    "        \n",
    "        # Extract the improved prompts\n",
    "        improved_triage_prompt = next(p[\"prompt\"] for p in result if p[\"name\"] == \"triage\")\n",
    "        improved_response_prompt = next(p[\"prompt\"] for p in result if p[\"name\"] == \"response\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"API error: {e}\")\n",
    "        print(\"Using manual prompt improvement as fallback\")\n",
    "        \n",
    "        # More specific manual improvements\n",
    "        improved_triage_prompt = triage_prompt + \"\\n\\nNote: Emails about API documentation or missing endpoints are high priority and should ALWAYS be classified as 'respond'.\"\n",
    "        improved_response_prompt = response_prompt + \"\\n\\nWhen responding to emails about documentation or API issues, acknowledge the specific issue mentioned and offer specific assistance rather than generic responses.\"\n",
    "\n",
    "    # Store the improved prompts\n",
    "    store.put((\"email_assistant\", user_id, \"prompts\"), \"triage_prompt\", improved_triage_prompt)\n",
    "    store.put((\"email_assistant\", user_id, \"prompts\"), \"response_prompt\", improved_response_prompt)\n",
    "\n",
    "    print(f\"Triage prompt improved: {improved_triage_prompt[:100]}...\")\n",
    "    print(f\"Response prompt improved: {improved_response_prompt[:100]}...\")\n",
    "\n",
    "    return \"Prompts improved based on feedback!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "triage:\n",
      "{'triage_result': 'respond'}\n",
      "-----\n",
      "-----\n",
      "response_agent:\n",
      "{'messages': [AIMessage(content='How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 307, 'total_tokens': 316, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BTFPEIyRnScGfoeO5yqFNe8sJuSvI', 'finish_reason': 'stop', 'logprobs': None}, id='run-9dab3135-0155-4f77-aba8-aa35df6f8295-0', usage_metadata={'input_tokens': 307, 'output_tokens': 9, 'total_tokens': 316, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "email_input = {\n",
    "    \"author\": \"Alice Smith <alice.smith@company.com>\",\n",
    "    \"to\": \"John Doe <john.doe@company.com>\",\n",
    "    \"subject\": \"Quick question about API documentation\",\n",
    "    \"email_thread\": \"\"\"Hi John,\n",
    "\n",
    "I was reviewing the API documentation and noticed a few endpoints are missing. Could you help?\n",
    "\n",
    "Thanks,\n",
    "Alice\"\"\",\n",
    "}\n",
    "\n",
    "config = {\"configurable\": {\"langgraph_user_id\": \"test_user\"}} # Set the user ID!\n",
    "inputs = {\"email_input\": email_input, \"messages\": []}\n",
    "\n",
    "for output in agent.stream(inputs, config=config): # Pass the config\n",
    "    for key, value in output.items():\n",
    "        print(f\"-----\\n{key}:\")\n",
    "        print(value)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add few shot examples to memory\n",
    "example1 = {\n",
    "    \"email\": {\n",
    "        \"author\": \"Spammy Marketer <spam@example.com>\",\n",
    "        \"to\": \"John Doe <john.doe@company.com>\",\n",
    "        \"subject\": \"BIG SALE!!!\",\n",
    "        \"email_thread\": \"Buy our product now and get 50% off!\",\n",
    "    },\n",
    "    \"label\": \"ignore\",\n",
    "}\n",
    "store.put((\"email_assistant\", \"test_user\", \"examples\"), \"spam_example\", example1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RUN THE CMPLETE THING NOW!!\n",
    "def create_email_agent(store):\n",
    "    # Define the workflow\n",
    "    workflow = StateGraph(State)\n",
    "    workflow.add_node(\"triage\", lambda state, config: triage_email_with_procedural_memory(state, config, store))\n",
    "\n",
    "    # Create a fresh response agent that will use the latest prompts\n",
    "    response_agent = create_react_agent(\n",
    "        tools=tools,\n",
    "        prompt=create_agent_prompt,\n",
    "        store=store,\n",
    "        model=llm\n",
    "    )\n",
    "\n",
    "    workflow.add_node('response_agent', response_agent)\n",
    "\n",
    "    # The routing logic reamis the same\n",
    "    workflow.add_edge(START, \"triage\")\n",
    "    workflow.add_conditional_edges(\"triage\", route_based_on_triage, {\"response_agent\": \"response_agent\", END:END})\n",
    "\n",
    "    # compile and return the graph\n",
    "    return workflow.compile(store=store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing original email BEFORE optimization...\n",
      "\n",
      "\n",
      "-----\n",
      "triage:\n",
      "{'triage_result': 'respond'}\n",
      "-----\n",
      "-----\n",
      "response_agent:\n",
      "{'messages': [AIMessage(content='How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 307, 'total_tokens': 316, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BTFXw675VwhnWv293MhGgRaFsaR5O', 'finish_reason': 'stop', 'logprobs': None}, id='run-04ca8eb4-96ad-450b-bd29-a20076a7f291-0', usage_metadata={'input_tokens': 307, 'output_tokens': 9, 'total_tokens': 316, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "-----\n",
      "Added API documentation example to episodic memory\n",
      "Triage prompt improved: You are an email triage assistant. Classify the following email:\n",
      "From: {author}\n",
      "To: {to}\n",
      "Subject: {s...\n",
      "Response prompt improved: You are a helpful assistant. Please prioritize specific contexts, such as API documentation inquirie...\n",
      "\n",
      "\n",
      "Processing the SAME email AFTER optimization with a fresh agent...\n",
      "\n",
      "\n",
      "-----\n",
      "triage:\n",
      "{'triage_result': 'respond'}\n",
      "-----\n",
      "-----\n",
      "response_agent:\n",
      "{'messages': [AIMessage(content='How can I assist you with API documentation or any specific inquiries you have today? If you have particular concerns or topics in mind, please let me know!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 329, 'total_tokens': 362, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'id': 'chatcmpl-BTFYO85TSEcAhGSgYnX9krPw2OHwp', 'finish_reason': 'stop', 'logprobs': None}, id='run-43511d5e-e5a4-4d4a-9b82-bf6539696686-0', usage_metadata={'input_tokens': 329, 'output_tokens': 33, 'total_tokens': 362, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# First process the original email to capture the \"before\" bahevior\n",
    "print(\"\\n\\nProcessing original email BEFORE optimization...\\n\\n\")\n",
    "agent = create_email_agent(store) #Create a fresh agent\n",
    "for output in agent.stream(inputs, config=config):\n",
    "    for key, value in output.items():\n",
    "        print(f\"-----\\n{key}:\")\n",
    "        print(value)\n",
    "    print(\"-----\")\n",
    "\n",
    "# Add a specific eample to episodic memory\n",
    "api_doc_example = {\n",
    "    \"email\": {\n",
    "        \"author\": \"Developer <dev@company.com>\",\n",
    "        \"to\": \"John Doe <john.doe@company.com>\",\n",
    "        \"subject\": \"API Documentation Issue\", \n",
    "        \"email_thread\": \"Found missing endpoints in the API docs. Need urgent update.\",\n",
    "    },\n",
    "    \"label\": \"respond\",\n",
    "}\n",
    "\n",
    "store.put((\"email_assistant\", \"test_user\", \"examples\"), \"api_doc_example\", api_doc_example)\n",
    "print(\"Added API documentation example to episodic memory\")\n",
    "\n",
    "# Provide feedback\n",
    "feedback = \"\"\"The agent didn't properly recognize that emails about API documentation issues \n",
    "are high priority and require immediate attention. When an email mentions \n",
    "'API documentation', it should always be classified as 'respond' with a helpful tone.\n",
    "Also, instead of just responding with 'How can I assist you today?', the agent should \n",
    "acknowledge the specific documentation issue mentioned and offer assistance.\"\"\"\n",
    "\n",
    "# OPtimize prompts\n",
    "optimize_prompts(feedback, config, store)\n",
    "\n",
    "# Process the SAME email after optimization with a FRESH agent\n",
    "print(\"\\n\\nProcessing the SAME email AFTER optimization with a fresh agent...\\n\\n\")\n",
    "new_agent = create_email_agent(store)  # Create a fresh agent with updated prompts\n",
    "for output in new_agent.stream(inputs, config=config):\n",
    "    for key, value in output.items():\n",
    "        print(f\"-----\\n{key}:\")\n",
    "        print(value)\n",
    "    print(\"-----\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agent World",
   "language": "python",
   "name": "agent_world"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
